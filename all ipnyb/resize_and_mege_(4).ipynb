{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # This will prompt you to upload the zip file again\n",
        "print(\"uploaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "PU_0j3lF4Z1t",
        "outputId": "c9671a59-0a06-485a-a7f0-50956c9fd913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8f616aa0-58bb-4cac-91b6-31fa6728da94\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8f616aa0-58bb-4cac-91b6-31fa6728da94\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving archive (2).zip to archive (2).zip\n",
            "uploaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Correct file path\n",
        "zip_path = \"/content/archive (2).zip\"\n",
        "\n",
        "# Extract to a new folder\n",
        "extract_path = \"/content/dental_AIUBdataset\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Extraction complete! Files are in: {extract_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhEoAkJ_5jx-",
        "outputId": "699a582c-2dac-43a7-ce4b-3db1e6ab7956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete! Files are in: /content/dental_AIUBdataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Path to the dataset directory\n",
        "dataset_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data'\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for root, dirs, files in os.walk(dataset_dir):\n",
        "    for file in files:\n",
        "        # Check if the file is an image (you can add more extensions if needed)\n",
        "        if file.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif')):\n",
        "            image_path = os.path.join(root, file)\n",
        "            with Image.open(image_path) as img:\n",
        "                width, height = img.size\n",
        "                print(f\"Image: {file} - Width: {width}, Height: {height}\")\n"
      ],
      "metadata": {
        "id": "kxhUjl2I0D9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7f0769-c6ba-43a0-9fb8-7a9a00238dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 18.jpg - Width: 1203, Height: 723\n",
            "Image: 169.jpg - Width: 1178, Height: 545\n",
            "Image: 189.jpg - Width: 1146, Height: 652\n",
            "Image: 166.jpg - Width: 1058, Height: 550\n",
            "Image: 58.jpg - Width: 962, Height: 592\n",
            "Image: 33.jpg - Width: 958, Height: 726\n",
            "Image: 107.jpg - Width: 870, Height: 358\n",
            "Image: 132.jpg - Width: 871, Height: 418\n",
            "Image: 237.jpg - Width: 1690, Height: 876\n",
            "Image: 9.jpg - Width: 1113, Height: 569\n",
            "Image: 259.jpg - Width: 1820, Height: 904\n",
            "Image: 134.jpg - Width: 1232, Height: 613\n",
            "Image: 83.jpg - Width: 1492, Height: 655\n",
            "Image: 121.jpg - Width: 1178, Height: 678\n",
            "Image: 144.jpg - Width: 651, Height: 328\n",
            "Image: 116.jpg - Width: 937, Height: 489\n",
            "Image: 193.jpg - Width: 867, Height: 477\n",
            "Image: 162.jpg - Width: 1144, Height: 523\n",
            "Image: 12.jpg - Width: 1175, Height: 603\n",
            "Image: 157.jpg - Width: 1066, Height: 489\n",
            "Image: 257.jpg - Width: 1840, Height: 885\n",
            "Image: 67.jpg - Width: 1174, Height: 517\n",
            "Image: 114.jpg - Width: 983, Height: 474\n",
            "Image: 213.jpg - Width: 1177, Height: 593\n",
            "Image: 22.jpg - Width: 945, Height: 584\n",
            "Image: 178.jpg - Width: 1496, Height: 802\n",
            "Image: 142.jpg - Width: 788, Height: 402\n",
            "Image: 46.jpg - Width: 1320, Height: 616\n",
            "Image: 159.jpg - Width: 1183, Height: 648\n",
            "Image: 215.jpg - Width: 1184, Height: 662\n",
            "Image: 156.jpg - Width: 774, Height: 324\n",
            "Image: 202.jpg - Width: 1316, Height: 678\n",
            "Image: 164.jpg - Width: 916, Height: 511\n",
            "Image: 117.jpg - Width: 1163, Height: 487\n",
            "Image: 141.jpg - Width: 899, Height: 439\n",
            "Image: 125.jpg - Width: 1230, Height: 516\n",
            "Image: 65.jpg - Width: 1134, Height: 524\n",
            "Image: 82.jpg - Width: 1184, Height: 574\n",
            "Image: 112.jpg - Width: 1142, Height: 529\n",
            "Image: 39.jpg - Width: 843, Height: 436\n",
            "Image: 13.jpg - Width: 1145, Height: 611\n",
            "Image: 184.jpg - Width: 1434, Height: 714\n",
            "Image: 52.jpg - Width: 1203, Height: 738\n",
            "Image: 40.jpg - Width: 1200, Height: 684\n",
            "Image: 84.jpg - Width: 1512, Height: 776\n",
            "Image: 20.jpg - Width: 1203, Height: 642\n",
            "Image: 138.jpg - Width: 995, Height: 528\n",
            "Image: 227.jpg - Width: 1179, Height: 625\n",
            "Image: 79.jpg - Width: 1156, Height: 572\n",
            "Image: 256.jpg - Width: 1878, Height: 891\n",
            "Image: 185.jpg - Width: 925, Height: 553\n",
            "Image: 59.jpg - Width: 923, Height: 463\n",
            "Image: 96.jpg - Width: 1988, Height: 1260\n",
            "Image: 239.jpg - Width: 1868, Height: 921\n",
            "Image: 196.jpg - Width: 1058, Height: 571\n",
            "Image: 245.jpg - Width: 1873, Height: 885\n",
            "Image: 248.jpg - Width: 1778, Height: 923\n",
            "Image: 41.jpg - Width: 1166, Height: 679\n",
            "Image: 124.jpg - Width: 1144, Height: 521\n",
            "Image: 8.jpg - Width: 1194, Height: 660\n",
            "Image: 115.jpg - Width: 1139, Height: 574\n",
            "Image: 172.jpg - Width: 940, Height: 454\n",
            "Image: 106.jpg - Width: 1038, Height: 540\n",
            "Image: 209.jpg - Width: 1111, Height: 581\n",
            "Image: 85.jpg - Width: 1372, Height: 583\n",
            "Image: 61.jpg - Width: 1590, Height: 831\n",
            "Image: 231.jpg - Width: 1888, Height: 916\n",
            "Image: 148.jpg - Width: 1044, Height: 496\n",
            "Image: 51.jpg - Width: 1200, Height: 745\n",
            "Image: 87.jpg - Width: 1434, Height: 766\n",
            "Image: 110.jpg - Width: 1199, Height: 547\n",
            "Image: 127.jpg - Width: 1210, Height: 519\n",
            "Image: 203.jpg - Width: 1179, Height: 650\n",
            "Image: 102.jpg - Width: 1228, Height: 560\n",
            "Image: 163.jpg - Width: 949, Height: 464\n",
            "Image: 233.jpg - Width: 1694, Height: 897\n",
            "Image: 1.jpg - Width: 1473, Height: 799\n",
            "Image: 62.jpg - Width: 1437, Height: 727\n",
            "Image: 73.jpg - Width: 1363, Height: 630\n",
            "Image: 191.jpg - Width: 1321, Height: 704\n",
            "Image: 95.jpg - Width: 755, Height: 436\n",
            "Image: 149.jpg - Width: 1078, Height: 462\n",
            "Image: 211.jpg - Width: 1148, Height: 569\n",
            "Image: 212.jpg - Width: 1175, Height: 623\n",
            "Image: 100.jpg - Width: 1739, Height: 905\n",
            "Image: 177.jpg - Width: 1280, Height: 698\n",
            "Image: 109.jpg - Width: 1197, Height: 532\n",
            "Image: 45.jpg - Width: 1203, Height: 608\n",
            "Image: 29.jpg - Width: 1198, Height: 642\n",
            "Image: 36.jpg - Width: 1200, Height: 669\n",
            "Image: 90.jpg - Width: 1369, Height: 613\n",
            "Image: 10.jpg - Width: 1155, Height: 591\n",
            "Image: 91.jpg - Width: 1525, Height: 697\n",
            "Image: 3.jpg - Width: 918, Height: 430\n",
            "Image: 246.jpg - Width: 1798, Height: 938\n",
            "Image: 238.jpg - Width: 1881, Height: 901\n",
            "Image: 235.jpg - Width: 1857, Height: 890\n",
            "Image: 260.jpg - Width: 1856, Height: 920\n",
            "Image: 139.jpg - Width: 1000, Height: 525\n",
            "Image: 66.jpg - Width: 978, Height: 496\n",
            "Image: 43.jpg - Width: 1200, Height: 672\n",
            "Image: 120.jpg - Width: 928, Height: 437\n",
            "Image: 122.jpg - Width: 1078, Height: 525\n",
            "Image: 30.jpg - Width: 1203, Height: 669\n",
            "Image: 180.jpg - Width: 1496, Height: 828\n",
            "Image: 11.jpg - Width: 1029, Height: 700\n",
            "Image: 199.jpg - Width: 1323, Height: 701\n",
            "Image: 128.jpg - Width: 1142, Height: 524\n",
            "Image: 205.jpg - Width: 1133, Height: 620\n",
            "Image: 68.jpg - Width: 1311, Height: 597\n",
            "Image: 75.jpg - Width: 1156, Height: 637\n",
            "Image: 208.jpg - Width: 845, Height: 466\n",
            "Image: 173.jpg - Width: 868, Height: 397\n",
            "Image: 228.jpg - Width: 1182, Height: 687\n",
            "Image: 188.jpg - Width: 832, Height: 472\n",
            "Image: 165.jpg - Width: 1110, Height: 513\n",
            "Image: 187.jpg - Width: 1600, Height: 900\n",
            "Image: 131.jpg - Width: 1492, Height: 626\n",
            "Image: 183.jpg - Width: 734, Height: 382\n",
            "Image: 225.jpg - Width: 1116, Height: 547\n",
            "Image: 119.jpg - Width: 1126, Height: 514\n",
            "Image: 101.jpg - Width: 1105, Height: 524\n",
            "Image: 57.jpg - Width: 962, Height: 596\n",
            "Image: 182.jpg - Width: 1554, Height: 808\n",
            "Image: 229.jpg - Width: 1009, Height: 506\n",
            "Image: 223.jpg - Width: 1155, Height: 584\n",
            "Image: 158.jpg - Width: 1171, Height: 684\n",
            "Image: 48.jpg - Width: 866, Height: 461\n",
            "Image: 133.jpg - Width: 1092, Height: 484\n",
            "Image: 92.jpg - Width: 1437, Height: 613\n",
            "Image: 34.jpg - Width: 1176, Height: 601\n",
            "Image: 88.jpg - Width: 919, Height: 359\n",
            "Image: 168.jpg - Width: 1149, Height: 464\n",
            "Image: 49.jpg - Width: 1203, Height: 699\n",
            "Image: 152.jpg - Width: 907, Height: 449\n",
            "Image: 113.jpg - Width: 1163, Height: 503\n",
            "Image: 217.jpg - Width: 1126, Height: 554\n",
            "Image: 236.jpg - Width: 1906, Height: 903\n",
            "Image: 170.jpg - Width: 940, Height: 432\n",
            "Image: 81.jpg - Width: 1723, Height: 922\n",
            "Image: 118.jpg - Width: 1137, Height: 503\n",
            "Image: 155.jpg - Width: 1107, Height: 503\n",
            "Image: 35.jpg - Width: 1200, Height: 721\n",
            "Image: 135.jpg - Width: 1320, Height: 623\n",
            "Image: 6.jpg - Width: 1189, Height: 640\n",
            "Image: 105.jpg - Width: 1176, Height: 579\n",
            "Image: 26.jpg - Width: 1203, Height: 642\n",
            "Image: 28.jpg - Width: 910, Height: 464\n",
            "Image: 176.jpg - Width: 843, Height: 442\n",
            "Image: 60.jpg - Width: 862, Height: 424\n",
            "Image: 160.jpg - Width: 1124, Height: 477\n",
            "Image: 23.jpg - Width: 1203, Height: 677\n",
            "Image: 243.jpg - Width: 1830, Height: 913\n",
            "Image: 218.jpg - Width: 1005, Height: 599\n",
            "Image: 24.jpg - Width: 1203, Height: 620\n",
            "Image: 253.jpg - Width: 1858, Height: 898\n",
            "Image: 103.jpg - Width: 1123, Height: 557\n",
            "Image: 220.jpg - Width: 947, Height: 466\n",
            "Image: 14.jpg - Width: 1177, Height: 650\n",
            "Image: 19.jpg - Width: 1203, Height: 596\n",
            "Image: 32.jpg - Width: 1203, Height: 633\n",
            "Image: 240.jpg - Width: 1902, Height: 850\n",
            "Image: 54.jpg - Width: 1276, Height: 766\n",
            "Image: 137.jpg - Width: 1313, Height: 580\n",
            "Image: 50.jpg - Width: 1203, Height: 701\n",
            "Image: 130.jpg - Width: 1157, Height: 503\n",
            "Image: 76.jpg - Width: 1201, Height: 747\n",
            "Image: 55.jpg - Width: 954, Height: 622\n",
            "Image: 64.jpg - Width: 1554, Height: 1004\n",
            "Image: 258.jpg - Width: 1869, Height: 901\n",
            "Image: 194.jpg - Width: 1252, Height: 664\n",
            "Image: 210.jpg - Width: 1386, Height: 715\n",
            "Image: 204.jpg - Width: 1170, Height: 623\n",
            "Image: 77.jpg - Width: 1185, Height: 521\n",
            "Image: 226.jpg - Width: 1457, Height: 802\n",
            "Image: 2.jpg - Width: 1157, Height: 591\n",
            "Image: 42.jpg - Width: 1203, Height: 640\n",
            "Image: 70.jpg - Width: 1379, Height: 747\n",
            "Image: 232.jpg - Width: 1908, Height: 907\n",
            "Image: 31.jpg - Width: 1138, Height: 674\n",
            "Image: 247.jpg - Width: 1836, Height: 890\n",
            "Image: 145.jpg - Width: 1056, Height: 450\n",
            "Image: 150.jpg - Width: 1146, Height: 706\n",
            "Image: 167.jpg - Width: 1112, Height: 557\n",
            "Image: 108.jpg - Width: 1079, Height: 532\n",
            "Image: 104.jpg - Width: 1019, Height: 545\n",
            "Image: 161.jpg - Width: 1141, Height: 455\n",
            "Image: 53.jpg - Width: 960, Height: 528\n",
            "Image: 71.jpg - Width: 1298, Height: 561\n",
            "Image: 146.jpg - Width: 1048, Height: 494\n",
            "Image: 86.jpg - Width: 1223, Height: 584\n",
            "Image: 98.jpg - Width: 802, Height: 330\n",
            "Image: 254.jpg - Width: 1945, Height: 907\n",
            "Image: 27.jpg - Width: 1203, Height: 736\n",
            "Image: 111.jpg - Width: 938, Height: 465\n",
            "Image: 153.jpg - Width: 1041, Height: 472\n",
            "Image: 252.jpg - Width: 1860, Height: 921\n",
            "Image: 214.jpg - Width: 1162, Height: 552\n",
            "Image: 15.jpg - Width: 1179, Height: 633\n",
            "Image: 97.jpg - Width: 890, Height: 373\n",
            "Image: 222.jpg - Width: 1172, Height: 692\n",
            "Image: 151.jpg - Width: 1075, Height: 491\n",
            "Image: 136.jpg - Width: 925, Height: 459\n",
            "Image: 129.jpg - Width: 1160, Height: 529\n",
            "Image: 242.jpg - Width: 1823, Height: 969\n",
            "Image: 201.jpg - Width: 497, Height: 259\n",
            "Image: 207.jpg - Width: 838, Height: 415\n",
            "Image: 234.jpg - Width: 1888, Height: 818\n",
            "Image: 21.jpg - Width: 1203, Height: 662\n",
            "Image: 72.jpg - Width: 1376, Height: 646\n",
            "Image: 56.jpg - Width: 934, Height: 530\n",
            "Image: 5.jpg - Width: 1184, Height: 618\n",
            "Image: 154.jpg - Width: 1088, Height: 452\n",
            "Image: 37.jpg - Width: 1191, Height: 606\n",
            "Image: 250.jpg - Width: 1898, Height: 908\n",
            "Image: 171.jpg - Width: 878, Height: 377\n",
            "Image: 143.jpg - Width: 864, Height: 475\n",
            "Image: 251.jpg - Width: 1847, Height: 906\n",
            "Image: 25.jpg - Width: 1203, Height: 642\n",
            "Image: 244.jpg - Width: 1781, Height: 942\n",
            "Image: 44.jpg - Width: 916, Height: 550\n",
            "Image: 123.jpg - Width: 1137, Height: 511\n",
            "Image: 94.jpg - Width: 1414, Height: 655\n",
            "Image: 80.jpg - Width: 786, Height: 377\n",
            "Image: 221.jpg - Width: 1126, Height: 655\n",
            "Image: 219.jpg - Width: 1150, Height: 589\n",
            "Image: 179.jpg - Width: 1522, Height: 772\n",
            "Image: 147.jpg - Width: 887, Height: 450\n",
            "Image: 241.jpg - Width: 1887, Height: 854\n",
            "Image: 230.jpg - Width: 1767, Height: 883\n",
            "Image: 93.jpg - Width: 1310, Height: 714\n",
            "Image: 38.jpg - Width: 1197, Height: 660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Path to the dataset directory\n",
        "dataset_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data'\n",
        "\n",
        "# Output directory for resized images\n",
        "output_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Desired size\n",
        "new_size = (512, 256)\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for root, dirs, files in os.walk(dataset_dir):\n",
        "    for file in files:\n",
        "        # Check if the file is an image (you can add more extensions if needed)\n",
        "        if file.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif')):\n",
        "            image_path = os.path.join(root, file)\n",
        "            with Image.open(image_path) as img:\n",
        "                # Resize the image to 512x256\n",
        "                resized_img = img.resize(new_size)\n",
        "\n",
        "                # Save the resized image to the output directory\n",
        "                output_path = os.path.join(output_dir, file)\n",
        "                resized_img.save(output_path)\n",
        "                print(f\"Resized and saved: {file} - New Size: {new_size}\")\n"
      ],
      "metadata": {
        "id": "GWL9TCtH1Odx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7412a1e0-5522-475d-aa63-726aedb60cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized and saved: 18.jpg - New Size: (512, 256)\n",
            "Resized and saved: 169.jpg - New Size: (512, 256)\n",
            "Resized and saved: 189.jpg - New Size: (512, 256)\n",
            "Resized and saved: 166.jpg - New Size: (512, 256)\n",
            "Resized and saved: 58.jpg - New Size: (512, 256)\n",
            "Resized and saved: 33.jpg - New Size: (512, 256)\n",
            "Resized and saved: 107.jpg - New Size: (512, 256)\n",
            "Resized and saved: 132.jpg - New Size: (512, 256)\n",
            "Resized and saved: 237.jpg - New Size: (512, 256)\n",
            "Resized and saved: 9.jpg - New Size: (512, 256)\n",
            "Resized and saved: 259.jpg - New Size: (512, 256)\n",
            "Resized and saved: 134.jpg - New Size: (512, 256)\n",
            "Resized and saved: 83.jpg - New Size: (512, 256)\n",
            "Resized and saved: 121.jpg - New Size: (512, 256)\n",
            "Resized and saved: 144.jpg - New Size: (512, 256)\n",
            "Resized and saved: 116.jpg - New Size: (512, 256)\n",
            "Resized and saved: 193.jpg - New Size: (512, 256)\n",
            "Resized and saved: 162.jpg - New Size: (512, 256)\n",
            "Resized and saved: 12.jpg - New Size: (512, 256)\n",
            "Resized and saved: 157.jpg - New Size: (512, 256)\n",
            "Resized and saved: 257.jpg - New Size: (512, 256)\n",
            "Resized and saved: 67.jpg - New Size: (512, 256)\n",
            "Resized and saved: 114.jpg - New Size: (512, 256)\n",
            "Resized and saved: 213.jpg - New Size: (512, 256)\n",
            "Resized and saved: 22.jpg - New Size: (512, 256)\n",
            "Resized and saved: 178.jpg - New Size: (512, 256)\n",
            "Resized and saved: 142.jpg - New Size: (512, 256)\n",
            "Resized and saved: 46.jpg - New Size: (512, 256)\n",
            "Resized and saved: 159.jpg - New Size: (512, 256)\n",
            "Resized and saved: 215.jpg - New Size: (512, 256)\n",
            "Resized and saved: 156.jpg - New Size: (512, 256)\n",
            "Resized and saved: 202.jpg - New Size: (512, 256)\n",
            "Resized and saved: 164.jpg - New Size: (512, 256)\n",
            "Resized and saved: 117.jpg - New Size: (512, 256)\n",
            "Resized and saved: 141.jpg - New Size: (512, 256)\n",
            "Resized and saved: 125.jpg - New Size: (512, 256)\n",
            "Resized and saved: 65.jpg - New Size: (512, 256)\n",
            "Resized and saved: 82.jpg - New Size: (512, 256)\n",
            "Resized and saved: 112.jpg - New Size: (512, 256)\n",
            "Resized and saved: 39.jpg - New Size: (512, 256)\n",
            "Resized and saved: 13.jpg - New Size: (512, 256)\n",
            "Resized and saved: 184.jpg - New Size: (512, 256)\n",
            "Resized and saved: 52.jpg - New Size: (512, 256)\n",
            "Resized and saved: 40.jpg - New Size: (512, 256)\n",
            "Resized and saved: 84.jpg - New Size: (512, 256)\n",
            "Resized and saved: 20.jpg - New Size: (512, 256)\n",
            "Resized and saved: 138.jpg - New Size: (512, 256)\n",
            "Resized and saved: 227.jpg - New Size: (512, 256)\n",
            "Resized and saved: 79.jpg - New Size: (512, 256)\n",
            "Resized and saved: 256.jpg - New Size: (512, 256)\n",
            "Resized and saved: 185.jpg - New Size: (512, 256)\n",
            "Resized and saved: 59.jpg - New Size: (512, 256)\n",
            "Resized and saved: 96.jpg - New Size: (512, 256)\n",
            "Resized and saved: 239.jpg - New Size: (512, 256)\n",
            "Resized and saved: 196.jpg - New Size: (512, 256)\n",
            "Resized and saved: 245.jpg - New Size: (512, 256)\n",
            "Resized and saved: 248.jpg - New Size: (512, 256)\n",
            "Resized and saved: 41.jpg - New Size: (512, 256)\n",
            "Resized and saved: 124.jpg - New Size: (512, 256)\n",
            "Resized and saved: 8.jpg - New Size: (512, 256)\n",
            "Resized and saved: 115.jpg - New Size: (512, 256)\n",
            "Resized and saved: 172.jpg - New Size: (512, 256)\n",
            "Resized and saved: 106.jpg - New Size: (512, 256)\n",
            "Resized and saved: 209.jpg - New Size: (512, 256)\n",
            "Resized and saved: 85.jpg - New Size: (512, 256)\n",
            "Resized and saved: 61.jpg - New Size: (512, 256)\n",
            "Resized and saved: 231.jpg - New Size: (512, 256)\n",
            "Resized and saved: 148.jpg - New Size: (512, 256)\n",
            "Resized and saved: 51.jpg - New Size: (512, 256)\n",
            "Resized and saved: 87.jpg - New Size: (512, 256)\n",
            "Resized and saved: 110.jpg - New Size: (512, 256)\n",
            "Resized and saved: 127.jpg - New Size: (512, 256)\n",
            "Resized and saved: 203.jpg - New Size: (512, 256)\n",
            "Resized and saved: 102.jpg - New Size: (512, 256)\n",
            "Resized and saved: 163.jpg - New Size: (512, 256)\n",
            "Resized and saved: 233.jpg - New Size: (512, 256)\n",
            "Resized and saved: 1.jpg - New Size: (512, 256)\n",
            "Resized and saved: 62.jpg - New Size: (512, 256)\n",
            "Resized and saved: 73.jpg - New Size: (512, 256)\n",
            "Resized and saved: 191.jpg - New Size: (512, 256)\n",
            "Resized and saved: 95.jpg - New Size: (512, 256)\n",
            "Resized and saved: 149.jpg - New Size: (512, 256)\n",
            "Resized and saved: 211.jpg - New Size: (512, 256)\n",
            "Resized and saved: 212.jpg - New Size: (512, 256)\n",
            "Resized and saved: 100.jpg - New Size: (512, 256)\n",
            "Resized and saved: 177.jpg - New Size: (512, 256)\n",
            "Resized and saved: 109.jpg - New Size: (512, 256)\n",
            "Resized and saved: 45.jpg - New Size: (512, 256)\n",
            "Resized and saved: 29.jpg - New Size: (512, 256)\n",
            "Resized and saved: 36.jpg - New Size: (512, 256)\n",
            "Resized and saved: 90.jpg - New Size: (512, 256)\n",
            "Resized and saved: 10.jpg - New Size: (512, 256)\n",
            "Resized and saved: 91.jpg - New Size: (512, 256)\n",
            "Resized and saved: 3.jpg - New Size: (512, 256)\n",
            "Resized and saved: 246.jpg - New Size: (512, 256)\n",
            "Resized and saved: 238.jpg - New Size: (512, 256)\n",
            "Resized and saved: 235.jpg - New Size: (512, 256)\n",
            "Resized and saved: 260.jpg - New Size: (512, 256)\n",
            "Resized and saved: 139.jpg - New Size: (512, 256)\n",
            "Resized and saved: 66.jpg - New Size: (512, 256)\n",
            "Resized and saved: 43.jpg - New Size: (512, 256)\n",
            "Resized and saved: 120.jpg - New Size: (512, 256)\n",
            "Resized and saved: 122.jpg - New Size: (512, 256)\n",
            "Resized and saved: 30.jpg - New Size: (512, 256)\n",
            "Resized and saved: 180.jpg - New Size: (512, 256)\n",
            "Resized and saved: 11.jpg - New Size: (512, 256)\n",
            "Resized and saved: 199.jpg - New Size: (512, 256)\n",
            "Resized and saved: 128.jpg - New Size: (512, 256)\n",
            "Resized and saved: 205.jpg - New Size: (512, 256)\n",
            "Resized and saved: 68.jpg - New Size: (512, 256)\n",
            "Resized and saved: 75.jpg - New Size: (512, 256)\n",
            "Resized and saved: 208.jpg - New Size: (512, 256)\n",
            "Resized and saved: 173.jpg - New Size: (512, 256)\n",
            "Resized and saved: 228.jpg - New Size: (512, 256)\n",
            "Resized and saved: 188.jpg - New Size: (512, 256)\n",
            "Resized and saved: 165.jpg - New Size: (512, 256)\n",
            "Resized and saved: 187.jpg - New Size: (512, 256)\n",
            "Resized and saved: 131.jpg - New Size: (512, 256)\n",
            "Resized and saved: 183.jpg - New Size: (512, 256)\n",
            "Resized and saved: 225.jpg - New Size: (512, 256)\n",
            "Resized and saved: 119.jpg - New Size: (512, 256)\n",
            "Resized and saved: 101.jpg - New Size: (512, 256)\n",
            "Resized and saved: 57.jpg - New Size: (512, 256)\n",
            "Resized and saved: 182.jpg - New Size: (512, 256)\n",
            "Resized and saved: 229.jpg - New Size: (512, 256)\n",
            "Resized and saved: 223.jpg - New Size: (512, 256)\n",
            "Resized and saved: 158.jpg - New Size: (512, 256)\n",
            "Resized and saved: 48.jpg - New Size: (512, 256)\n",
            "Resized and saved: 133.jpg - New Size: (512, 256)\n",
            "Resized and saved: 92.jpg - New Size: (512, 256)\n",
            "Resized and saved: 34.jpg - New Size: (512, 256)\n",
            "Resized and saved: 88.jpg - New Size: (512, 256)\n",
            "Resized and saved: 168.jpg - New Size: (512, 256)\n",
            "Resized and saved: 49.jpg - New Size: (512, 256)\n",
            "Resized and saved: 152.jpg - New Size: (512, 256)\n",
            "Resized and saved: 113.jpg - New Size: (512, 256)\n",
            "Resized and saved: 217.jpg - New Size: (512, 256)\n",
            "Resized and saved: 236.jpg - New Size: (512, 256)\n",
            "Resized and saved: 170.jpg - New Size: (512, 256)\n",
            "Resized and saved: 81.jpg - New Size: (512, 256)\n",
            "Resized and saved: 118.jpg - New Size: (512, 256)\n",
            "Resized and saved: 155.jpg - New Size: (512, 256)\n",
            "Resized and saved: 35.jpg - New Size: (512, 256)\n",
            "Resized and saved: 135.jpg - New Size: (512, 256)\n",
            "Resized and saved: 6.jpg - New Size: (512, 256)\n",
            "Resized and saved: 105.jpg - New Size: (512, 256)\n",
            "Resized and saved: 26.jpg - New Size: (512, 256)\n",
            "Resized and saved: 28.jpg - New Size: (512, 256)\n",
            "Resized and saved: 176.jpg - New Size: (512, 256)\n",
            "Resized and saved: 60.jpg - New Size: (512, 256)\n",
            "Resized and saved: 160.jpg - New Size: (512, 256)\n",
            "Resized and saved: 23.jpg - New Size: (512, 256)\n",
            "Resized and saved: 243.jpg - New Size: (512, 256)\n",
            "Resized and saved: 218.jpg - New Size: (512, 256)\n",
            "Resized and saved: 24.jpg - New Size: (512, 256)\n",
            "Resized and saved: 253.jpg - New Size: (512, 256)\n",
            "Resized and saved: 103.jpg - New Size: (512, 256)\n",
            "Resized and saved: 220.jpg - New Size: (512, 256)\n",
            "Resized and saved: 14.jpg - New Size: (512, 256)\n",
            "Resized and saved: 19.jpg - New Size: (512, 256)\n",
            "Resized and saved: 32.jpg - New Size: (512, 256)\n",
            "Resized and saved: 240.jpg - New Size: (512, 256)\n",
            "Resized and saved: 54.jpg - New Size: (512, 256)\n",
            "Resized and saved: 137.jpg - New Size: (512, 256)\n",
            "Resized and saved: 50.jpg - New Size: (512, 256)\n",
            "Resized and saved: 130.jpg - New Size: (512, 256)\n",
            "Resized and saved: 76.jpg - New Size: (512, 256)\n",
            "Resized and saved: 55.jpg - New Size: (512, 256)\n",
            "Resized and saved: 64.jpg - New Size: (512, 256)\n",
            "Resized and saved: 258.jpg - New Size: (512, 256)\n",
            "Resized and saved: 194.jpg - New Size: (512, 256)\n",
            "Resized and saved: 210.jpg - New Size: (512, 256)\n",
            "Resized and saved: 204.jpg - New Size: (512, 256)\n",
            "Resized and saved: 77.jpg - New Size: (512, 256)\n",
            "Resized and saved: 226.jpg - New Size: (512, 256)\n",
            "Resized and saved: 2.jpg - New Size: (512, 256)\n",
            "Resized and saved: 42.jpg - New Size: (512, 256)\n",
            "Resized and saved: 70.jpg - New Size: (512, 256)\n",
            "Resized and saved: 232.jpg - New Size: (512, 256)\n",
            "Resized and saved: 31.jpg - New Size: (512, 256)\n",
            "Resized and saved: 247.jpg - New Size: (512, 256)\n",
            "Resized and saved: 145.jpg - New Size: (512, 256)\n",
            "Resized and saved: 150.jpg - New Size: (512, 256)\n",
            "Resized and saved: 167.jpg - New Size: (512, 256)\n",
            "Resized and saved: 108.jpg - New Size: (512, 256)\n",
            "Resized and saved: 104.jpg - New Size: (512, 256)\n",
            "Resized and saved: 161.jpg - New Size: (512, 256)\n",
            "Resized and saved: 53.jpg - New Size: (512, 256)\n",
            "Resized and saved: 71.jpg - New Size: (512, 256)\n",
            "Resized and saved: 146.jpg - New Size: (512, 256)\n",
            "Resized and saved: 86.jpg - New Size: (512, 256)\n",
            "Resized and saved: 98.jpg - New Size: (512, 256)\n",
            "Resized and saved: 254.jpg - New Size: (512, 256)\n",
            "Resized and saved: 27.jpg - New Size: (512, 256)\n",
            "Resized and saved: 111.jpg - New Size: (512, 256)\n",
            "Resized and saved: 153.jpg - New Size: (512, 256)\n",
            "Resized and saved: 252.jpg - New Size: (512, 256)\n",
            "Resized and saved: 214.jpg - New Size: (512, 256)\n",
            "Resized and saved: 15.jpg - New Size: (512, 256)\n",
            "Resized and saved: 97.jpg - New Size: (512, 256)\n",
            "Resized and saved: 222.jpg - New Size: (512, 256)\n",
            "Resized and saved: 151.jpg - New Size: (512, 256)\n",
            "Resized and saved: 136.jpg - New Size: (512, 256)\n",
            "Resized and saved: 129.jpg - New Size: (512, 256)\n",
            "Resized and saved: 242.jpg - New Size: (512, 256)\n",
            "Resized and saved: 201.jpg - New Size: (512, 256)\n",
            "Resized and saved: 207.jpg - New Size: (512, 256)\n",
            "Resized and saved: 234.jpg - New Size: (512, 256)\n",
            "Resized and saved: 21.jpg - New Size: (512, 256)\n",
            "Resized and saved: 72.jpg - New Size: (512, 256)\n",
            "Resized and saved: 56.jpg - New Size: (512, 256)\n",
            "Resized and saved: 5.jpg - New Size: (512, 256)\n",
            "Resized and saved: 154.jpg - New Size: (512, 256)\n",
            "Resized and saved: 37.jpg - New Size: (512, 256)\n",
            "Resized and saved: 250.jpg - New Size: (512, 256)\n",
            "Resized and saved: 171.jpg - New Size: (512, 256)\n",
            "Resized and saved: 143.jpg - New Size: (512, 256)\n",
            "Resized and saved: 251.jpg - New Size: (512, 256)\n",
            "Resized and saved: 25.jpg - New Size: (512, 256)\n",
            "Resized and saved: 244.jpg - New Size: (512, 256)\n",
            "Resized and saved: 44.jpg - New Size: (512, 256)\n",
            "Resized and saved: 123.jpg - New Size: (512, 256)\n",
            "Resized and saved: 94.jpg - New Size: (512, 256)\n",
            "Resized and saved: 80.jpg - New Size: (512, 256)\n",
            "Resized and saved: 221.jpg - New Size: (512, 256)\n",
            "Resized and saved: 219.jpg - New Size: (512, 256)\n",
            "Resized and saved: 179.jpg - New Size: (512, 256)\n",
            "Resized and saved: 147.jpg - New Size: (512, 256)\n",
            "Resized and saved: 241.jpg - New Size: (512, 256)\n",
            "Resized and saved: 230.jpg - New Size: (512, 256)\n",
            "Resized and saved: 93.jpg - New Size: (512, 256)\n",
            "Resized and saved: 38.jpg - New Size: (512, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Target image size\n",
        "TARGET_WIDTH = 512\n",
        "TARGET_HEIGHT = 256\n",
        "\n",
        "# Folder paths\n",
        "input_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data'  # Your image and .txt files folder\n",
        "output_folder = os.path.join(input_folder, 'converted_csvs')\n",
        "\n",
        "# Make output directory if not exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Allowed image extensions\n",
        "image_extensions = ['.jpg', '.jpeg', '.png']\n",
        "\n",
        "# Helper to find matching image\n",
        "def find_image_file(base_name):\n",
        "    for ext in image_extensions:\n",
        "        candidate = os.path.join(input_folder, base_name + ext)\n",
        "        if os.path.exists(candidate):\n",
        "            return candidate\n",
        "    return None\n",
        "\n",
        "# Process each annotation .txt file\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.txt'):\n",
        "        base_name = os.path.splitext(filename)[0]\n",
        "        image_path = find_image_file(base_name)\n",
        "\n",
        "        if image_path is None:\n",
        "            print(f\"❌ Image not found for {filename}, skipping.\")\n",
        "            continue\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"❌ Could not read image {image_path}, skipping.\")\n",
        "            continue\n",
        "\n",
        "        orig_height, orig_width = image.shape[:2]\n",
        "        scale_x = TARGET_WIDTH / orig_width\n",
        "        scale_y = TARGET_HEIGHT / orig_height\n",
        "\n",
        "        input_file = os.path.join(input_folder, filename)\n",
        "        output_file = os.path.join(output_folder, base_name + '_converted.csv')\n",
        "\n",
        "        with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "            # Write header with width and height included\n",
        "            outfile.write(\"class_id,xmin,ymin,xmax,ymax,width,height\\n\")\n",
        "\n",
        "            for line in infile:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) != 5:\n",
        "                    continue\n",
        "\n",
        "                class_id, x_center, y_center, width, height = map(float, parts)\n",
        "\n",
        "                # Original pixel coordinates\n",
        "                x_center *= orig_width\n",
        "                y_center *= orig_height\n",
        "                width *= orig_width\n",
        "                height *= orig_height\n",
        "\n",
        "                xmin = x_center - width / 2\n",
        "                ymin = y_center - height / 2\n",
        "                xmax = x_center + width / 2\n",
        "                ymax = y_center + height / 2\n",
        "\n",
        "                # Resize to target dimensions\n",
        "                xmin *= scale_x\n",
        "                ymin *= scale_y\n",
        "                xmax *= scale_x\n",
        "                ymax *= scale_y\n",
        "\n",
        "                # Final output width and height\n",
        "                outfile.write(f\"{int(class_id)},{int(xmin)},{int(ymin)},{int(xmax)},{int(ymax)},{TARGET_WIDTH},{TARGET_HEIGHT}\\n\")\n",
        "\n",
        "print(f\"✅ All converted CSVs saved to: {output_folder}\")\n"
      ],
      "metadata": {
        "id": "dyV2H_wp8XrM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6078aa08-3a4c-4c8e-e9a8-07cfc93eb286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All converted CSVs saved to: /content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for class 1,2"
      ],
      "metadata": {
        "id": "FV0qo9iWa724"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Folder paths\n",
        "input_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs'  # Where your converted CSVs are stored\n",
        "output_folder = 'class1,2csv'  # New folder for filtered files\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Process each CSV file\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('_converted.csv'):\n",
        "        file_path = os.path.join(input_folder, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Filter only class_id 2 and 3\n",
        "        filtered_df = df[df['class_id'].isin([1, 2])]\n",
        "\n",
        "        # If any rows match, save them\n",
        "        if not filtered_df.empty:\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            filtered_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"✅ Class 1and 2 annotations saved to: {output_folder}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEwCVt1S_qM6",
        "outputId": "14799d7c-12c5-4dee-bab0-418ccd35c3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Class 1and 2 annotations saved to: class1,2csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Input/output folders\n",
        "input_folder = '/content/class1,2csv'\n",
        "output_folder = 'classNamecsv12'\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Class ID to class name mapping\n",
        "class_mapping = {\n",
        "    1: \"Cavity\",\n",
        "    2: \"Impacted tooth\"\n",
        "}\n",
        "\n",
        "# Process each CSV\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Replace class ID with class name\n",
        "        df['class_id'] = df['class_id'].map(class_mapping)\n",
        "\n",
        "        # Rename the column from class_id to class_name\n",
        "        df.rename(columns={'class_id': 'class_name'}, inplace=True)\n",
        "\n",
        "        # Save to output\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        df.to_csv(output_path, index=False)\n",
        "\n",
        "\n",
        "print(f\"✅ Class names replaced and saved to: {output_folder}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGU5X61fAdCQ",
        "outputId": "b204b3c7-8421-4529-deb6-d2c5a76ff9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Class names replaced and saved to: classNamecsv12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# Folder containing final CSVs with class_name\n",
        "input_folder = '/content/classNamecsv12'\n",
        "\n",
        "# Track image count per class\n",
        "class_image_count = defaultdict(int)\n",
        "\n",
        "# Process each CSV file\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Get the unique classes in this image\n",
        "        unique_classes = df['class_name'].unique()\n",
        "\n",
        "        # Increment image count for each class found\n",
        "        for cls in unique_classes:\n",
        "            class_image_count[cls] += 1\n",
        "\n",
        "# Print results\n",
        "print(\"📊 Number of images per class:\")\n",
        "for cls, count in class_image_count.items():\n",
        "    print(f\"  {cls}: {count} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqeFf4RFB66o",
        "outputId": "073dd968-4e18-4c70-985e-f7d932de3b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Number of images per class:\n",
            "  Cavity: 23 images\n",
            "  Impacted tooth: 87 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Folder containing your CSV files\n",
        "input_folder = '/content/classNamecsv12'\n",
        "\n",
        "# Output Excel file path\n",
        "output_excel_path = './combined_class_named_data.xlsx'\n",
        "\n",
        "# List to track all CSV filenames\n",
        "csv_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
        "\n",
        "# Create an Excel writer object with openpyxl engine\n",
        "with pd.ExcelWriter(output_excel_path, engine='openpyxl') as writer:\n",
        "    for filename in csv_files:\n",
        "        file_path = os.path.join(input_folder, filename)\n",
        "\n",
        "        # Debug: Check if file is being read correctly\n",
        "        print(f\"Reading file: {file_path}\")\n",
        "\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Debug: Print first few rows of the DataFrame to ensure data is being read\n",
        "        print(f\"First few rows in {filename}:\\n\", df.head())\n",
        "\n",
        "        # Use the filename (without extension) as the sheet name\n",
        "        sheet_name = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Write each CSV as a separate sheet in the Excel file\n",
        "        df.to_excel(writer, sheet_name=sheet_name[:31], index=False)\n",
        "\n",
        "print(f\"✅ All CSV files combined into Excel at: {output_excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmBimVuUDiYE",
        "outputId": "3bf49b65-b53c-4a13-f537-6a26b5be801b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading file: /content/classNamecsv12/188_converted.csv\n",
            "First few rows in 188_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0          Cavity   314   127   370   205    512     256\n",
            "1  Impacted tooth   404   103   445   146    512     256\n",
            "2  Impacted tooth   359    62   401   106    512     256\n",
            "3  Impacted tooth   312   161   359   191    512     256\n",
            "4  Impacted tooth   115    60   152   104    512     256\n",
            "Reading file: /content/classNamecsv12/36_converted.csv\n",
            "First few rows in 36_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    70   146   120   186    512     256\n",
            "1  Impacted tooth   364   149   414   193    512     256\n",
            "2  Impacted tooth   345    83   382   130    512     256\n",
            "Reading file: /content/classNamecsv12/193_converted.csv\n",
            "First few rows in 193_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   346    47   389    90    512     256\n",
            "1  Impacted tooth   375   112   418   151    512     256\n",
            "2  Impacted tooth    84   114   127   154    512     256\n",
            "3  Impacted tooth   104    59   147    99    512     256\n",
            "Reading file: /content/classNamecsv12/30_converted.csv\n",
            "First few rows in 30_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   114    57   149    95    512     256\n",
            "1  Impacted tooth   390   125   439   167    512     256\n",
            "2  Impacted tooth   366    62   404   103    512     256\n",
            "3  Impacted tooth    90   115   132   156    512     256\n",
            "Reading file: /content/classNamecsv12/156_converted.csv\n",
            "First few rows in 156_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   104   161   155   207    512     256\n",
            "1  Impacted tooth   402   159   446   199    512     256\n",
            "Reading file: /content/classNamecsv12/84_converted.csv\n",
            "First few rows in 84_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   192    88   232   144    512     256\n",
            "1     Cavity   283    87   317   145    512     256\n",
            "Reading file: /content/classNamecsv12/137_converted.csv\n",
            "First few rows in 137_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   377   129   424   169    512     256\n",
            "Reading file: /content/classNamecsv12/2_converted.csv\n",
            "First few rows in 2_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0          Cavity   157   164   201   221    512     256\n",
            "1  Impacted tooth   386   103   413   147    512     256\n",
            "2  Impacted tooth   125    96   158   143    512     256\n",
            "3  Impacted tooth   110   160   151   200    512     256\n",
            "4  Impacted tooth   384   163   422   200    512     256\n",
            "Reading file: /content/classNamecsv12/6_converted.csv\n",
            "First few rows in 6_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   378   149   432   184    512     256\n",
            "1  Impacted tooth    83   155   135   191    512     256\n",
            "Reading file: /content/classNamecsv12/12_converted.csv\n",
            "First few rows in 12_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    92    86   138   132    512     256\n",
            "Reading file: /content/classNamecsv12/199_converted.csv\n",
            "First few rows in 199_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0          Cavity   363   124   414   175    512     256\n",
            "1  Impacted tooth   374    79   406   119    512     256\n",
            "2  Impacted tooth   104   136   136   173    512     256\n",
            "Reading file: /content/classNamecsv12/104_converted.csv\n",
            "First few rows in 104_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   384   158   429   205    512     256\n",
            "Reading file: /content/classNamecsv12/225_converted.csv\n",
            "First few rows in 225_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    92   110   121   146    512     256\n",
            "1  Impacted tooth   372    95   399   135    512     256\n",
            "Reading file: /content/classNamecsv12/23_converted.csv\n",
            "First few rows in 23_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   385    89   415   133    512     256\n",
            "1  Impacted tooth    81   137   129   175    512     256\n",
            "2  Impacted tooth   142   174   169   215    512     256\n",
            "Reading file: /content/classNamecsv12/209_converted.csv\n",
            "First few rows in 209_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   102   175   151   217    512     256\n",
            "1  Impacted tooth   394   124   432   166    512     256\n",
            "2  Impacted tooth   110   108   148   149    512     256\n",
            "Reading file: /content/classNamecsv12/194_converted.csv\n",
            "First few rows in 194_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   332    45   382    96    512     256\n",
            "1          Cavity   137   175   183   234    512     256\n",
            "2          Cavity   313   167   371   226    512     256\n",
            "Reading file: /content/classNamecsv12/158_converted.csv\n",
            "First few rows in 158_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   370   143   414   189    512     256\n",
            "1  Impacted tooth   111    61   154   111    512     256\n",
            "2  Impacted tooth    86   150   134   190    512     256\n",
            "3  Impacted tooth   351    62   399   114    512     256\n",
            "Reading file: /content/classNamecsv12/102_converted.csv\n",
            "First few rows in 102_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   407   138   443   183    512     256\n",
            "1  Impacted tooth   121   132   152   181    512     256\n",
            "2  Impacted tooth   122    57   154    94    512     256\n",
            "Reading file: /content/classNamecsv12/145_converted.csv\n",
            "First few rows in 145_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   102   132   146   181    512     256\n",
            "Reading file: /content/classNamecsv12/203_converted.csv\n",
            "First few rows in 203_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   102   175   163   217    512     256\n",
            "1          Cavity   171    88   211   150    512     256\n",
            "2  Impacted tooth   391   169   451   216    512     256\n",
            "Reading file: /content/classNamecsv12/148_converted.csv\n",
            "First few rows in 148_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   102    38   142    99    512     256\n",
            "1  Impacted tooth   386    36   425    97    512     256\n",
            "Reading file: /content/classNamecsv12/177_converted.csv\n",
            "First few rows in 177_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   391    84   425   124    512     256\n",
            "1  Impacted tooth   392   148   437   193    512     256\n",
            "Reading file: /content/classNamecsv12/219_converted.csv\n",
            "First few rows in 219_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   199   124   233   195    512     256\n",
            "1     Cavity   257   128   288   203    512     256\n",
            "Reading file: /content/classNamecsv12/189_converted.csv\n",
            "First few rows in 189_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   379   129   423   164    512     256\n",
            "Reading file: /content/classNamecsv12/229_converted.csv\n",
            "First few rows in 229_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   182    97   211   167    512     256\n",
            "Reading file: /content/classNamecsv12/152_converted.csv\n",
            "First few rows in 152_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    60   148   103   204    512     256\n",
            "Reading file: /content/classNamecsv12/83_converted.csv\n",
            "First few rows in 83_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   393   123   446   174    512     256\n",
            "Reading file: /content/classNamecsv12/171_converted.csv\n",
            "First few rows in 171_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   120    48   161   109    512     256\n",
            "1  Impacted tooth   108   139   151   196    512     256\n",
            "2  Impacted tooth   383   150   425   199    512     256\n",
            "3  Impacted tooth   377    55   411   116    512     256\n",
            "Reading file: /content/classNamecsv12/204_converted.csv\n",
            "First few rows in 204_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    83   157   131   196    512     256\n",
            "1  Impacted tooth   386   152   434   191    512     256\n",
            "Reading file: /content/classNamecsv12/205_converted.csv\n",
            "First few rows in 205_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   276    62   324   110    512     256\n",
            "1     Cavity   206    59   254   106    512     256\n",
            "Reading file: /content/classNamecsv12/218_converted.csv\n",
            "First few rows in 218_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   223   160   251   239    512     256\n",
            "1     Cavity   239   157   271   237    512     256\n",
            "Reading file: /content/classNamecsv12/32_converted.csv\n",
            "First few rows in 32_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    98   155   139   202    512     256\n",
            "1  Impacted tooth   390   159   437   202    512     256\n",
            "2  Impacted tooth   109    90   154   140    512     256\n",
            "3  Impacted tooth   385    93   419   136    512     256\n",
            "Reading file: /content/classNamecsv12/127_converted.csv\n",
            "First few rows in 127_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   381    54   416   105    512     256\n",
            "Reading file: /content/classNamecsv12/86_converted.csv\n",
            "First few rows in 86_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   119   127   153   169    512     256\n",
            "1  Impacted tooth   403   127   438   173    512     256\n",
            "2  Impacted tooth   125    51   158    84    512     256\n",
            "Reading file: /content/classNamecsv12/180_converted.csv\n",
            "First few rows in 180_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    95   154   142   212    512     256\n",
            "Reading file: /content/classNamecsv12/58_converted.csv\n",
            "First few rows in 58_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   395   158   440   191    512     256\n",
            "1  Impacted tooth    79   153   118   195    512     256\n",
            "Reading file: /content/classNamecsv12/70_converted.csv\n",
            "First few rows in 70_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   182    89   228   146    512     256\n",
            "1     Cavity   296    91   334   145    512     256\n",
            "Reading file: /content/classNamecsv12/176_converted.csv\n",
            "First few rows in 176_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   118   111   156   144    512     256\n",
            "1  Impacted tooth   372   103   400   138    512     256\n",
            "2  Impacted tooth    99   177   140   214    512     256\n",
            "3  Impacted tooth   379   174   423   216    512     256\n",
            "Reading file: /content/classNamecsv12/170_converted.csv\n",
            "First few rows in 170_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   384   140   422   178    512     256\n",
            "1  Impacted tooth   377    70   409   112    512     256\n",
            "Reading file: /content/classNamecsv12/5_converted.csv\n",
            "First few rows in 5_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   373   179   417   218    512     256\n",
            "1  Impacted tooth    98   100   141   140    512     256\n",
            "2  Impacted tooth    80   177   123   220    512     256\n",
            "Reading file: /content/classNamecsv12/116_converted.csv\n",
            "First few rows in 116_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   394   134   437   183    512     256\n",
            "1  Impacted tooth   110   146   151   203    512     256\n",
            "Reading file: /content/classNamecsv12/82_converted.csv\n",
            "First few rows in 82_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    98   118   143   154    512     256\n",
            "1  Impacted tooth   385   116   435   158    512     256\n",
            "Reading file: /content/classNamecsv12/220_converted.csv\n",
            "First few rows in 220_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   395    67   442   128    512     256\n",
            "1  Impacted tooth    80    62   115   123    512     256\n",
            "2  Impacted tooth    61   144   110   192    512     256\n",
            "Reading file: /content/classNamecsv12/133_converted.csv\n",
            "First few rows in 133_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   375   122   419   167    512     256\n",
            "Reading file: /content/classNamecsv12/49_converted.csv\n",
            "First few rows in 49_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   377   149   418   192    512     256\n",
            "1  Impacted tooth   361    98   392   130    512     256\n",
            "2  Impacted tooth   112    98   137   135    512     256\n",
            "3  Impacted tooth    71   143   124   180    512     256\n",
            "Reading file: /content/classNamecsv12/77_converted.csv\n",
            "First few rows in 77_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   283   144   314   217    512     256\n",
            "1     Cavity   197    31   246   109    512     256\n",
            "2     Cavity   276    39   343    98    512     256\n",
            "Reading file: /content/classNamecsv12/162_converted.csv\n",
            "First few rows in 162_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   398    40   420    71    512     256\n",
            "1  Impacted tooth    74   120   117   170    512     256\n",
            "Reading file: /content/classNamecsv12/66_converted.csv\n",
            "First few rows in 66_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   386   147   433   187    512     256\n",
            "Reading file: /content/classNamecsv12/214_converted.csv\n",
            "First few rows in 214_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    95   144   139   197    512     256\n",
            "1  Impacted tooth   384   142   434   181    512     256\n",
            "2  Impacted tooth   365    72   401   112    512     256\n",
            "Reading file: /content/classNamecsv12/75_converted.csv\n",
            "First few rows in 75_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   109    47   150    95    512     256\n",
            "Reading file: /content/classNamecsv12/87_converted.csv\n",
            "First few rows in 87_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   292    94   323   146    512     256\n",
            "1     Cavity   181    95   219   145    512     256\n",
            "Reading file: /content/classNamecsv12/108_converted.csv\n",
            "First few rows in 108_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   421   118   469   169    512     256\n",
            "1  Impacted tooth    92   123   143   165    512     256\n",
            "Reading file: /content/classNamecsv12/128_converted.csv\n",
            "First few rows in 128_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   384   125   432   169    512     256\n",
            "1  Impacted tooth    87   125   129   165    512     256\n",
            "Reading file: /content/classNamecsv12/15_converted.csv\n",
            "First few rows in 15_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   370   142   425   184    512     256\n",
            "Reading file: /content/classNamecsv12/196_converted.csv\n",
            "First few rows in 196_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0          Cavity   336    79   385   125    512     256\n",
            "1  Impacted tooth   382   150   425   185    512     256\n",
            "2          Cavity   272    76   321   122    512     256\n",
            "Reading file: /content/classNamecsv12/10_converted.csv\n",
            "First few rows in 10_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    87   152   140   196    512     256\n",
            "Reading file: /content/classNamecsv12/115_converted.csv\n",
            "First few rows in 115_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    81   124   139   171    512     256\n",
            "Reading file: /content/classNamecsv12/13_converted.csv\n",
            "First few rows in 13_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    87   179   135   227    512     256\n",
            "1  Impacted tooth   382   168   438   215    512     256\n",
            "Reading file: /content/classNamecsv12/92_converted.csv\n",
            "First few rows in 92_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   383   111   421   169    512     256\n",
            "Reading file: /content/classNamecsv12/25_converted.csv\n",
            "First few rows in 25_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   381   178   422   229    512     256\n",
            "1  Impacted tooth   374   111   413   152    512     256\n",
            "2  Impacted tooth    96   103   137   149    512     256\n",
            "Reading file: /content/classNamecsv12/85_converted.csv\n",
            "First few rows in 85_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0          Cavity   141   125   178   207    512     256\n",
            "1  Impacted tooth   369    49   403    91    512     256\n",
            "2  Impacted tooth   388   116   419   160    512     256\n",
            "3  Impacted tooth   114    53   145    91    512     256\n",
            "4  Impacted tooth    96   118   129   160    512     256\n",
            "Reading file: /content/classNamecsv12/250_converted.csv\n",
            "First few rows in 250_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    82   120   119   176    512     256\n",
            "Reading file: /content/classNamecsv12/166_converted.csv\n",
            "First few rows in 166_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    71    99   106   138    512     256\n",
            "1  Impacted tooth   402    98   442   141    512     256\n",
            "2  Impacted tooth   401   157   454   195    512     256\n",
            "3  Impacted tooth    67   143   110   191    512     256\n",
            "Reading file: /content/classNamecsv12/153_converted.csv\n",
            "First few rows in 153_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   104    54   137    99    512     256\n",
            "1  Impacted tooth    86   137   126   190    512     256\n",
            "2  Impacted tooth   173   151   202   207    512     256\n",
            "3  Impacted tooth   403   134   441   185    512     256\n",
            "4  Impacted tooth   397    55   425    99    512     256\n",
            "Reading file: /content/classNamecsv12/98_converted.csv\n",
            "First few rows in 98_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   367   136   396   183    512     256\n",
            "Reading file: /content/classNamecsv12/62_converted.csv\n",
            "First few rows in 62_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   394   118   432   162    512     256\n",
            "Reading file: /content/classNamecsv12/163_converted.csv\n",
            "First few rows in 163_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   377   139   421   187    512     256\n",
            "Reading file: /content/classNamecsv12/55_converted.csv\n",
            "First few rows in 55_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   397   118   476   164    512     256\n",
            "Reading file: /content/classNamecsv12/202_converted.csv\n",
            "First few rows in 202_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    74   141   123   183    512     256\n",
            "Reading file: /content/classNamecsv12/260_converted.csv\n",
            "First few rows in 260_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   132   139   192   228    512     256\n",
            "Reading file: /content/classNamecsv12/169_converted.csv\n",
            "First few rows in 169_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   111    49   144   101    512     256\n",
            "1  Impacted tooth   368    62   405   111    512     256\n",
            "2  Impacted tooth   381   140   428   181    512     256\n",
            "3  Impacted tooth    91   132   139   181    512     256\n",
            "Reading file: /content/classNamecsv12/135_converted.csv\n",
            "First few rows in 135_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   359    80   391   123    512     256\n",
            "Reading file: /content/classNamecsv12/165_converted.csv\n",
            "First few rows in 165_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    88   135   137   201    512     256\n",
            "Reading file: /content/classNamecsv12/172_converted.csv\n",
            "First few rows in 172_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    59   139   105   187    512     256\n",
            "1  Impacted tooth   403   142   452   184    512     256\n",
            "Reading file: /content/classNamecsv12/122_converted.csv\n",
            "First few rows in 122_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   124    68   169   116    512     256\n",
            "1  Impacted tooth   368    71   411   118    512     256\n",
            "2  Impacted tooth   366   146   415   195    512     256\n",
            "Reading file: /content/classNamecsv12/253_converted.csv\n",
            "First few rows in 253_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   367   132   416   178    512     256\n",
            "1  Impacted tooth   110    61   143   114    512     256\n",
            "2  Impacted tooth   105   134   143   184    512     256\n",
            "Reading file: /content/classNamecsv12/161_converted.csv\n",
            "First few rows in 161_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   396   136   436   190    512     256\n",
            "Reading file: /content/classNamecsv12/187_converted.csv\n",
            "First few rows in 187_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   373    99   407   139    512     256\n",
            "1  Impacted tooth   113   108   142   148    512     256\n",
            "Reading file: /content/classNamecsv12/42_converted.csv\n",
            "First few rows in 42_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   101   107   141   140    512     256\n",
            "1  Impacted tooth   376   104   419   147    512     256\n",
            "Reading file: /content/classNamecsv12/114_converted.csv\n",
            "First few rows in 114_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   203   129   234   190    512     256\n",
            "1     Cavity   223   132   247   218    512     256\n",
            "Reading file: /content/classNamecsv12/201_converted.csv\n",
            "First few rows in 201_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   373    99   412   135    512     256\n",
            "1  Impacted tooth   104   100   144   136    512     256\n",
            "Reading file: /content/classNamecsv12/211_converted.csv\n",
            "First few rows in 211_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    99    44   144   102    512     256\n",
            "1  Impacted tooth    69   135   120   191    512     256\n",
            "2  Impacted tooth   403   138   449   180    512     256\n",
            "Reading file: /content/classNamecsv12/8_converted.csv\n",
            "First few rows in 8_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   159    41   247    92    512     256\n",
            "1     Cavity   275    49   369    95    512     256\n",
            "Reading file: /content/classNamecsv12/164_converted.csv\n",
            "First few rows in 164_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   397   152   445   191    512     256\n",
            "1  Impacted tooth    69   153   114   195    512     256\n",
            "2  Impacted tooth    75    97   120   136    512     256\n",
            "Reading file: /content/classNamecsv12/131_converted.csv\n",
            "First few rows in 131_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   406    90   449   149    512     256\n",
            "Reading file: /content/classNamecsv12/64_converted.csv\n",
            "First few rows in 64_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   166   168   200   221    512     256\n",
            "1     Cavity   322   164   359   215    512     256\n",
            "Reading file: /content/classNamecsv12/60_converted.csv\n",
            "First few rows in 60_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   106   155   151   202    512     256\n",
            "1  Impacted tooth   162   188   196   224    512     256\n",
            "2  Impacted tooth   203   193   239   246    512     256\n",
            "3  Impacted tooth   260   187   296   246    512     256\n",
            "4  Impacted tooth   347   158   396   203    512     256\n",
            "Reading file: /content/classNamecsv12/112_converted.csv\n",
            "First few rows in 112_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   366   129   418   178    512     256\n",
            "1  Impacted tooth   348    51   390   105    512     256\n",
            "Reading file: /content/classNamecsv12/191_converted.csv\n",
            "First few rows in 191_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   376   126   421   163    512     256\n",
            "1  Impacted tooth    88   113   136   153    512     256\n",
            "Reading file: /content/classNamecsv12/68_converted.csv\n",
            "First few rows in 68_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   385   123   416   163    512     256\n",
            "1  Impacted tooth   367    60   397    94    512     256\n",
            "2  Impacted tooth    80   124   112   164    512     256\n",
            "3  Impacted tooth    96    58   129    96    512     256\n",
            "4          Cavity   125   128   163   202    512     256\n",
            "Reading file: /content/classNamecsv12/223_converted.csv\n",
            "First few rows in 223_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   379   171   430   224    512     256\n",
            "Reading file: /content/classNamecsv12/110_converted.csv\n",
            "First few rows in 110_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   393   113   435   164    512     256\n",
            "1  Impacted tooth    69   132   110   190    512     256\n",
            "Reading file: /content/classNamecsv12/173_converted.csv\n",
            "First few rows in 173_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth    96   140   130   197    512     256\n",
            "Reading file: /content/classNamecsv12/208_converted.csv\n",
            "First few rows in 208_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   381   138   439   178    512     256\n",
            "Reading file: /content/classNamecsv12/154_converted.csv\n",
            "First few rows in 154_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   403   129   441   181    512     256\n",
            "1  Impacted tooth    81   113   115   170    512     256\n",
            "Reading file: /content/classNamecsv12/123_converted.csv\n",
            "First few rows in 123_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   389   130   428   177    512     256\n",
            "1  Impacted tooth    97   123   129   168    512     256\n",
            "Reading file: /content/classNamecsv12/88_converted.csv\n",
            "First few rows in 88_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   390    42   426   103    512     256\n",
            "1  Impacted tooth   117    78   148   142    512     256\n",
            "2  Impacted tooth    84   141   133   206    512     256\n",
            "Reading file: /content/classNamecsv12/28_converted.csv\n",
            "First few rows in 28_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   298   164   370   230    512     256\n",
            "1     Cavity   169   173   244   239    512     256\n",
            "Reading file: /content/classNamecsv12/1_converted.csv\n",
            "First few rows in 1_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   225   138   254   203    512     256\n",
            "Reading file: /content/classNamecsv12/45_converted.csv\n",
            "First few rows in 45_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   108   145   145   184    512     256\n",
            "1  Impacted tooth   127    81   162   118    512     256\n",
            "2  Impacted tooth   388   148   430   184    512     256\n",
            "3  Impacted tooth   377    82   415   121    512     256\n",
            "Reading file: /content/classNamecsv12/46_converted.csv\n",
            "First few rows in 46_converted.csv:\n",
            "        class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0  Impacted tooth   126    62   158   114    512     256\n",
            "1  Impacted tooth   364    58   399   112    512     256\n",
            "Reading file: /content/classNamecsv12/222_converted.csv\n",
            "First few rows in 222_converted.csv:\n",
            "   class_name  xmin  ymin  xmax  ymax  width  height\n",
            "0     Cavity   114   149   169   212    512     256\n",
            "✅ All CSV files combined into Excel at: ./combined_class_named_data.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Paths to your original images folder and destination for train, test, valid\n",
        "input_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images'\n",
        "train_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/train'\n",
        "test_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/test'\n",
        "valid_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/valid'\n",
        "\n",
        "# Create train, test, valid folders if they don't exist\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "os.makedirs(valid_folder, exist_ok=True)\n",
        "\n",
        "# Get all image filenames in the input folder\n",
        "image_files = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]\n",
        "\n",
        "# Shuffle the list of image files to ensure random splitting\n",
        "random.shuffle(image_files)\n",
        "\n",
        "# Define split proportions\n",
        "train_split = 0.7\n",
        "test_split = 0.15\n",
        "valid_split = 0.15\n",
        "\n",
        "# Calculate the number of files for each split\n",
        "train_size = int(len(image_files) * train_split)\n",
        "test_size = int(len(image_files) * test_split)\n",
        "valid_size = len(image_files) - train_size - test_size\n",
        "\n",
        "# Split the image files\n",
        "train_images = image_files[:train_size]\n",
        "test_images = image_files[train_size:train_size + test_size]\n",
        "valid_images = image_files[train_size + test_size:]\n",
        "\n",
        "# Function to move files to the respective folder\n",
        "def move_images(images, destination_folder):\n",
        "    for image in images:\n",
        "        src_path = os.path.join(input_folder, image)\n",
        "        dest_path = os.path.join(destination_folder, image)\n",
        "        shutil.move(src_path, dest_path)\n",
        "\n",
        "# Move the images to the respective folders\n",
        "move_images(train_images, train_folder)\n",
        "move_images(test_images, test_folder)\n",
        "move_images(valid_images, valid_folder)\n",
        "\n",
        "print(f\"✅ Images split into train, test, and valid folders!\")\n",
        "print(f\"  - {len(train_images)} images in the train folder\")\n",
        "print(f\"  - {len(test_images)} images in the test folder\")\n",
        "print(f\"  - {len(valid_images)} images in the valid folder\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64Q0jOgXGuZO",
        "outputId": "fdca02f2-b460-4659-c3aa-8890dd336986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Images split into train, test, and valid folders!\n",
            "  - 162 images in the train folder\n",
            "  - 34 images in the test folder\n",
            "  - 36 images in the valid folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Folder containing your CSV files\n",
        "input_folder = '/content/classNamecsv12'\n",
        "\n",
        "# Output Excel file path\n",
        "output_excel_path = './final_combined_annotations.xlsx'\n",
        "\n",
        "# List to collect DataFrames\n",
        "all_data = []\n",
        "\n",
        "# Iterate over all CSVs\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(input_folder, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Extract image name from filename (e.g., \"abc.csv\" -> \"abc.jpg\")\n",
        "        image_name = os.path.splitext(filename)[0] + '.jpg'\n",
        "\n",
        "        # Add image name as a new column\n",
        "        df.insert(0, 'image_name', image_name)\n",
        "\n",
        "        # Append to the list\n",
        "        all_data.append(df)\n",
        "\n",
        "# Concatenate all dataframes into one\n",
        "combined_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# Save to Excel file\n",
        "combined_df.to_excel(output_excel_path, index=False)\n",
        "\n",
        "print(f\"✅ Combined all annotations into a single Excel file: {output_excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5jGheqkKg88",
        "outputId": "d601fbd6-82d8-4bc1-9c66-12e90cc08d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Combined all annotations into a single Excel file: ./final_combined_annotations.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking number of imgs"
      ],
      "metadata": {
        "id": "hoOVrm8sOdsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('./final_combined_annotations.xlsx')  # Or .csv if that's what you used\n",
        "print(df['class_name'].value_counts())\n",
        "print(\"\\nUnique image count per class:\")\n",
        "print(df.groupby('class_name')['image_name'].nunique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObfJBPziNuyL",
        "outputId": "6d02fa8d-9ec7-4222-9397-1e65f1c597a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_name\n",
            "Impacted tooth    198\n",
            "Cavity             37\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique image count per class:\n",
            "class_name\n",
            "Cavity            23\n",
            "Impacted tooth    87\n",
            "Name: image_name, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"CSV files in :/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs\")\n",
        "print(len([f for f in os.listdir('/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs') if f.endswith('.csv')]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oer6xpVGOo38",
        "outputId": "4ddedd96-a5f2-4611-b08f-7bb308a638c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files in :/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs\n",
            "232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Path to your folder containing multiple CSVs\n",
        "csv_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs'\n",
        "\n",
        "# Initialize counter\n",
        "impacted_tooth_count = 0\n",
        "\n",
        "# Loop through all CSV files\n",
        "for file in os.listdir(csv_folder):\n",
        "    if file.endswith('.csv'):\n",
        "        df = pd.read_csv(os.path.join(csv_folder, file))\n",
        "        impacted_tooth_count += (df['class_id'] == 3).sum()\n",
        "\n",
        "print(f\"✅ Total 'Impacted tooth' annotations (class_id = 3): {impacted_tooth_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPj2KLaHSOOY",
        "outputId": "bf47df0a-f2af-4586-86cc-962c66784080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Total 'Impacted tooth' annotations (class_id = 3): 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking for all class"
      ],
      "metadata": {
        "id": "sCNOz7MEWFgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Folder path\n",
        "csv_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs'\n",
        "\n",
        "# Set to collect unique class IDs\n",
        "all_class_ids = set()\n",
        "\n",
        "# Loop through all CSVs and collect class_id values\n",
        "for file in os.listdir(csv_folder):\n",
        "    if file.endswith('.csv'):\n",
        "        df = pd.read_csv(os.path.join(csv_folder, file))\n",
        "        if 'class_id' in df.columns:\n",
        "            all_class_ids.update(df['class_id'].unique())\n",
        "\n",
        "# Sort and display\n",
        "all_class_ids = sorted(all_class_ids)\n",
        "print(f\"✅ Unique class IDs found in dataset: {all_class_ids}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAQV3t_6TGbc",
        "outputId": "461aceb8-7988-48a7-e204-54e753e250f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Unique class IDs found in dataset: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Input folder where your converted CSVs are\n",
        "input_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs'\n",
        "\n",
        "# Base output directory where class-wise folders will be created\n",
        "output_base = '/content/class_wise_csvs'\n",
        "os.makedirs(output_base, exist_ok=True)\n",
        "\n",
        "# Process each CSV file\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('_converted.csv'):\n",
        "        file_path = os.path.join(input_folder, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Get all unique class_ids in this file\n",
        "        for class_id in df['class_id'].unique():\n",
        "            # Filter rows for this specific class_id\n",
        "            filtered_df = df[df['class_id'] == class_id]\n",
        "\n",
        "            # Prepare output folder for this class\n",
        "            class_folder = os.path.join(output_base, f'class_{int(class_id)}')\n",
        "            os.makedirs(class_folder, exist_ok=True)\n",
        "\n",
        "            # Save filtered CSV for this file\n",
        "            output_path = os.path.join(class_folder, filename)\n",
        "            filtered_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"✅ All class-wise CSVs saved inside: {output_base}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDHnuylTWLsQ",
        "outputId": "09c71003-7384-4c34-f3b1-3be0b20c2372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All class-wise CSVs saved inside: /content/class_wise_csvs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Mapping from class ID to class name\n",
        "class_map = {\n",
        "    0: 'Healthy teeth',\n",
        "    1: 'Cavity',\n",
        "    2: 'Impacted Tooth',\n",
        "    3: 'BDC',\n",
        "    4: 'Infection',\n",
        "    5: 'Fractured teeth'\n",
        "}\n",
        "\n",
        "# Input and output paths\n",
        "input_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs'\n",
        "output_base = '/content/class_named_csvs'\n",
        "os.makedirs(output_base, exist_ok=True)\n",
        "\n",
        "# Process each CSV file\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('_converted.csv'):\n",
        "        file_path = os.path.join(input_folder, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Replace class_id with class name\n",
        "        df['class_name'] = df['class_id'].map(class_map)\n",
        "\n",
        "        # Loop through each class and save separately\n",
        "        for class_name in df['class_name'].unique():\n",
        "            filtered_df = df[df['class_name'] == class_name]\n",
        "\n",
        "            # Create folder for this class name\n",
        "            class_folder = os.path.join(output_base, class_name.replace(\" \", \"_\"))\n",
        "            os.makedirs(class_folder, exist_ok=True)\n",
        "\n",
        "            # Save the filtered CSV\n",
        "            output_path = os.path.join(class_folder, filename)\n",
        "            filtered_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"✅ Class-named CSVs saved in: {output_base}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0EXsFKnXPut",
        "outputId": "36f74cd7-d633-4d8c-d72f-7be468b98905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Class-named CSVs saved in: /content/class_named_csvs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Base path where class-wise folders are stored\n",
        "base_path = '/content/class_wise_csvs'\n",
        "\n",
        "# Dictionary to hold counts\n",
        "class_counts = {}\n",
        "\n",
        "# Loop through each class folder\n",
        "for class_folder in os.listdir(base_path):\n",
        "    folder_path = os.path.join(base_path, class_folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        total_rows = 0\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.endswith('.csv'):\n",
        "                df = pd.read_csv(os.path.join(folder_path, file))\n",
        "                total_rows += len(df)\n",
        "        class_counts[class_folder.replace(\"_\", \" \")] = total_rows\n",
        "\n",
        "# Display the results\n",
        "print(\"✅ Annotation count per class:\\n\")\n",
        "for class_name, count in class_counts.items():\n",
        "    print(f\"{class_name}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrDUqPofXhAf",
        "outputId": "1a5a48a2-e577-43b7-b5ce-0638399ce9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Annotation count per class:\n",
            "\n",
            "class 1: 37\n",
            "class 3: 14\n",
            "class 2: 198\n",
            "class 0: 198\n",
            "class 5: 654\n",
            "class 4: 103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Mapping from class ID to class name\n",
        "class_map = {\n",
        "    0: 'Healthy teeth',\n",
        "    1: 'Cavity',\n",
        "    2: 'Impacted Tooth',\n",
        "    3: 'BDC/BDR',\n",
        "    4: 'Infection',\n",
        "    5: 'Fractured teeth'\n",
        "}\n",
        "\n",
        "# Base path where class-wise folders are stored\n",
        "base_path = '/content/class_named_csvs'\n",
        "\n",
        "# List to hold data\n",
        "data = []\n",
        "\n",
        "# Loop through each class folder\n",
        "for class_folder in os.listdir(base_path):\n",
        "    folder_path = os.path.join(base_path, class_folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Process each CSV in the class folder\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.endswith('.csv'):\n",
        "                df = pd.read_csv(os.path.join(folder_path, file))\n",
        "\n",
        "                # Replace class_id with class_name\n",
        "                df['class_name'] = df['class_id'].map(class_map)\n",
        "\n",
        "                # Collect necessary columns and add image name\n",
        "                df['image_name'] = file  # Add the image name to each row\n",
        "\n",
        "                # Append relevant columns to the data list\n",
        "                for _, row in df.iterrows():\n",
        "                    data.append([row['image_name'], row['class_name'], row['xmin'], row['ymin'], row['xmax'], row['ymax'], row['width'], row['height']])\n",
        "\n",
        "# Convert the collected data to a DataFrame\n",
        "df_output = pd.DataFrame(data, columns=['image_name', 'class_name', 'xmin', 'ymin', 'xmax', 'ymax', 'width', 'height'])\n",
        "\n",
        "# Save to Excel\n",
        "output_excel_path = '/content/class_image_data.xlsx'\n",
        "df_output.to_excel(output_excel_path, index=False)\n",
        "\n",
        "print(f\"✅ Excel file with image data saved at: {output_excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRqotMylaPjs",
        "outputId": "fe5a16f3-05e2-475c-d2d7-b85be99ebd12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Excel file with image data saved at: /content/class_image_data.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dropping the healthy teeth and bdr class"
      ],
      "metadata": {
        "id": "kuT9-ZgKWbdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Mapping from class ID to class name\n",
        "class_map = {\n",
        "    0: 'Healthy teeth',\n",
        "    1: 'Cavity',\n",
        "    2: 'Impacted Tooth',\n",
        "    3: 'BDC/BDR',\n",
        "    4: 'Infection',\n",
        "    5: 'Fractured teeth'\n",
        "}\n",
        "\n",
        "# Folder containing class-wise CSVs\n",
        "base_path = '/content/class_named_csvs'\n",
        "\n",
        "# List to collect all rows\n",
        "data = []\n",
        "\n",
        "# Loop through each class folder\n",
        "for class_folder in os.listdir(base_path):\n",
        "    folder_path = os.path.join(base_path, class_folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.endswith('.csv'):\n",
        "                csv_path = os.path.join(folder_path, file)\n",
        "                df = pd.read_csv(csv_path)\n",
        "\n",
        "                # Drop rows with class_id 0 (Healthy teeth) and 3 (BDC/BDR)\n",
        "                df = df[~df['class_id'].isin([0, 3])]\n",
        "\n",
        "                # Map class_id to class_name\n",
        "                df['class_name'] = df['class_id'].map(class_map)\n",
        "\n",
        "                # Add image name\n",
        "                df['image_name'] = file\n",
        "\n",
        "                # Select relevant columns\n",
        "                df_selected = df[['image_name', 'class_name', 'xmin', 'ymin', 'xmax', 'ymax', 'width', 'height']]\n",
        "\n",
        "                data.append(df_selected)\n",
        "\n",
        "# Concatenate all into a single DataFrame\n",
        "final_df = pd.concat(data, ignore_index=True)\n",
        "\n",
        "# Save to Excel\n",
        "output_excel = '/content/filtered_class_image_data.xlsx'\n",
        "final_df.to_excel(output_excel, index=False)\n",
        "\n",
        "print(f\"✅ Excel file created without 'Healthy teeth' and 'BDC/BDR' classes at: {output_excel}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EpZSJqbV6uf",
        "outputId": "04a92161-62bf-4861-addb-79c7efa74dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Excel file created without 'Healthy teeth' and 'BDC/BDR' classes at: /content/filtered_class_image_data.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to your CSV directory\n",
        "csv_dir = '/content/class_named_csvs'\n",
        "\n",
        "# Counter\n",
        "csv_count = 0\n",
        "\n",
        "# Loop through subfolders and count CSV files\n",
        "for root, dirs, files in os.walk(csv_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.csv'):\n",
        "            csv_count += 1\n",
        "\n",
        "print(f\"📄 Total number of CSV files in '{csv_dir}': {csv_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee43b0xfWYFH",
        "outputId": "38fa09d7-b9fc-4787-c141-dbab61bcbae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Total number of CSV files in '/content/class_named_csvs': 517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spliting the excel file"
      ],
      "metadata": {
        "id": "XGSv9QTIWiFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "csv_path = '/content/filtered_class_image_data.xlsx'  # or .csv\n",
        "train_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/train'\n",
        "test_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/test'\n",
        "val_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/valid'\n",
        "\n",
        "# Read the original Excel or CSV file\n",
        "if csv_path.endswith('.xlsx'):\n",
        "    df = pd.read_excel(csv_path)\n",
        "else:\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "# Assuming your image names are in a column called 'image_name'\n",
        "# Adjust the column name if different\n",
        "image_column = 'image_name'\n",
        "\n",
        "# Helper to get image names from a folder\n",
        "def get_image_names(folder):\n",
        "    return set(os.listdir(folder))\n",
        "\n",
        "# Get image names from folders\n",
        "train_images = get_image_names(train_dir)\n",
        "test_images = get_image_names(test_dir)\n",
        "val_images = get_image_names(val_dir)\n",
        "\n",
        "# Filter based on image names\n",
        "train_df = df[df[image_column].isin(train_images)]\n",
        "test_df = df[df[image_column].isin(test_images)]\n",
        "val_df = df[df[image_column].isin(val_images)]\n",
        "\n",
        "# Save to new files\n",
        "train_df.to_csv('train_data.csv', index=False)\n",
        "test_df.to_csv('test_data.csv', index=False)\n",
        "val_df.to_csv('val_data.csv', index=False)\n",
        "\n",
        "print(\"CSV files created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0SXKBGtWnAF",
        "outputId": "af0da690-36b1-4cd5-8521-1cb23ca77356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "moving the csvs to the respective folders"
      ],
      "metadata": {
        "id": "g-aTUTdliwmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Step 1: Load Excel file\n",
        "csv_path = '/content/filtered_class_image_data.xlsx'\n",
        "df = pd.read_excel(csv_path)\n",
        "\n",
        "# Step 2: Create a new column with updated image names for matching\n",
        "df['match_name'] = df['image_name'].str.replace('_converted.csv', '.jpg', regex=False)\n",
        "\n",
        "# Step 3: Define paths to image folders\n",
        "train_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/train'\n",
        "test_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/test'\n",
        "val_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/valid'\n",
        "\n",
        "# Step 4: Get filenames from each folder\n",
        "def get_image_names(folder):\n",
        "    return set(os.listdir(folder))\n",
        "\n",
        "train_images = get_image_names(train_folder)\n",
        "test_images = get_image_names(test_folder)\n",
        "val_images = get_image_names(val_folder)\n",
        "\n",
        "# Step 5: Filter DataFrame for each split\n",
        "train_df = df[df['match_name'].isin(train_images)]\n",
        "test_df = df[df['match_name'].isin(test_images)]\n",
        "val_df = df[df['match_name'].isin(val_images)]\n",
        "\n",
        "# Step 6: Save to CSVs in respective folders\n",
        "train_df.to_csv(os.path.join(train_folder, 'train_data.csv'), index=False)\n",
        "test_df.to_csv(os.path.join(test_folder, 'test_data.csv'), index=False)\n",
        "val_df.to_csv(os.path.join(val_folder, 'val_data.csv'), index=False)\n",
        "\n",
        "print(\"✅ CSVs saved to their respective image folders.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyMHUh_hl1kF",
        "outputId": "c7837c32-ca3a-4f2b-adc5-9ce8652ce398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSVs saved to their respective image folders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('Resized_Images', 'zip', '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fN5eDmxKyOTG",
        "outputId": "0a04db19-9d7d-4889-bd96-219995048e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Resized_Images.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('Resized_Images.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "alHvE4JIysYL",
        "outputId": "c64bc7f7-387c-4729-a1bb-e3d28533a7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1d0be165-6419-4452-82b5-12e126164a26\", \"Resized_Images.zip\", 6344208)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}