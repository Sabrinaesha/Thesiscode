# -*- coding: utf-8 -*-
"""resize_and_mege (4).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/199zPhq7p-9s7rek_ekOTlr23qgB912f-
"""

from google.colab import files

uploaded = files.upload()  # This will prompt you to upload the zip file again
print("uploaded")

import zipfile
import os

# Correct file path
zip_path = "/content/archive (2).zip"

# Extract to a new folder
extract_path = "/content/dental_AIUBdataset"
os.makedirs(extract_path, exist_ok=True)

with zipfile.ZipFile(zip_path, "r") as zip_ref:
    zip_ref.extractall(extract_path)

print(f"Extraction complete! Files are in: {extract_path}")

import os
from PIL import Image

# Path to the dataset directory
dataset_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data'

# Loop through all files in the directory
for root, dirs, files in os.walk(dataset_dir):
    for file in files:
        # Check if the file is an image (you can add more extensions if needed)
        if file.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif')):
            image_path = os.path.join(root, file)
            with Image.open(image_path) as img:
                width, height = img.size
                print(f"Image: {file} - Width: {width}, Height: {height}")

import os
from PIL import Image

# Path to the dataset directory
dataset_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data'

# Output directory for resized images
output_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images'
os.makedirs(output_dir, exist_ok=True)

# Desired size
new_size = (512, 256)

# Loop through all files in the directory
for root, dirs, files in os.walk(dataset_dir):
    for file in files:
        # Check if the file is an image (you can add more extensions if needed)
        if file.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif')):
            image_path = os.path.join(root, file)
            with Image.open(image_path) as img:
                # Resize the image to 512x256
                resized_img = img.resize(new_size)

                # Save the resized image to the output directory
                output_path = os.path.join(output_dir, file)
                resized_img.save(output_path)
                print(f"Resized and saved: {file} - New Size: {new_size}")

import os
import cv2

# Target image size
TARGET_WIDTH = 512
TARGET_HEIGHT = 256

# Folder paths
input_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data'  # Your image and .txt files folder
output_folder = os.path.join(input_folder, 'converted_csvs')

# Make output directory if not exist
os.makedirs(output_folder, exist_ok=True)

# Allowed image extensions
image_extensions = ['.jpg', '.jpeg', '.png']

# Helper to find matching image
def find_image_file(base_name):
    for ext in image_extensions:
        candidate = os.path.join(input_folder, base_name + ext)
        if os.path.exists(candidate):
            return candidate
    return None

# Process each annotation .txt file
for filename in os.listdir(input_folder):
    if filename.endswith('.txt'):
        base_name = os.path.splitext(filename)[0]
        image_path = find_image_file(base_name)

        if image_path is None:
            print(f"âŒ Image not found for {filename}, skipping.")
            continue

        image = cv2.imread(image_path)
        if image is None:
            print(f"âŒ Could not read image {image_path}, skipping.")
            continue

        orig_height, orig_width = image.shape[:2]
        scale_x = TARGET_WIDTH / orig_width
        scale_y = TARGET_HEIGHT / orig_height

        input_file = os.path.join(input_folder, filename)
        output_file = os.path.join(output_folder, base_name + '_converted.csv')

        with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:
            # Write header with width and height included
            outfile.write("class_id,xmin,ymin,xmax,ymax,width,height\n")

            for line in infile:
                parts = line.strip().split()
                if len(parts) != 5:
                    continue

                class_id, x_center, y_center, width, height = map(float, parts)

                # Original pixel coordinates
                x_center *= orig_width
                y_center *= orig_height
                width *= orig_width
                height *= orig_height

                xmin = x_center - width / 2
                ymin = y_center - height / 2
                xmax = x_center + width / 2
                ymax = y_center + height / 2

                # Resize to target dimensions
                xmin *= scale_x
                ymin *= scale_y
                xmax *= scale_x
                ymax *= scale_y

                # Final output width and height
                outfile.write(f"{int(class_id)},{int(xmin)},{int(ymin)},{int(xmax)},{int(ymax)},{TARGET_WIDTH},{TARGET_HEIGHT}\n")

print(f"âœ… All converted CSVs saved to: {output_folder}")

"""for class 1,2"""

import os
import pandas as pd

# Folder paths
input_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs'  # Where your converted CSVs are stored
output_folder = 'class1,2csv'  # New folder for filtered files

# Create output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Process each CSV file
for filename in os.listdir(input_folder):
    if filename.endswith('_converted.csv'):
        file_path = os.path.join(input_folder, filename)
        df = pd.read_csv(file_path)

        # Filter only class_id 2 and 3
        filtered_df = df[df['class_id'].isin([1, 2])]

        # If any rows match, save them
        if not filtered_df.empty:
            output_path = os.path.join(output_folder, filename)
            filtered_df.to_csv(output_path, index=False)

print(f"âœ… Class 1and 2 annotations saved to: {output_folder}")

import os
import pandas as pd

# Input/output folders
input_folder = '/content/class1,2csv'
output_folder = 'classNamecsv12'

# Create output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Class ID to class name mapping
class_mapping = {
    1: "Cavity",
    2: "Impacted tooth"
}

# Process each CSV
for filename in os.listdir(input_folder):
    if filename.endswith('.csv'):
        file_path = os.path.join(input_folder, filename)
        df = pd.read_csv(file_path)

        # Replace class ID with class name
        df['class_id'] = df['class_id'].map(class_mapping)

        # Rename the column from class_id to class_name
        df.rename(columns={'class_id': 'class_name'}, inplace=True)

        # Save to output
        output_path = os.path.join(output_folder, filename)
        df.to_csv(output_path, index=False)


print(f"âœ… Class names replaced and saved to: {output_folder}")

import os
import pandas as pd
from collections import defaultdict

# Folder containing final CSVs with class_name
input_folder = '/content/classNamecsv12'

# Track image count per class
class_image_count = defaultdict(int)

# Process each CSV file
for filename in os.listdir(input_folder):
    if filename.endswith('.csv'):
        file_path = os.path.join(input_folder, filename)
        df = pd.read_csv(file_path)

        # Get the unique classes in this image
        unique_classes = df['class_name'].unique()

        # Increment image count for each class found
        for cls in unique_classes:
            class_image_count[cls] += 1

# Print results
print("ðŸ“Š Number of images per class:")
for cls, count in class_image_count.items():
    print(f"  {cls}: {count} images")

import os
import pandas as pd

# Folder containing your CSV files
input_folder = '/content/classNamecsv12'

# Output Excel file path
output_excel_path = './combined_class_named_data.xlsx'

# List to track all CSV filenames
csv_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]

# Create an Excel writer object with openpyxl engine
with pd.ExcelWriter(output_excel_path, engine='openpyxl') as writer:
    for filename in csv_files:
        file_path = os.path.join(input_folder, filename)

        # Debug: Check if file is being read correctly
        print(f"Reading file: {file_path}")

        df = pd.read_csv(file_path)

        # Debug: Print first few rows of the DataFrame to ensure data is being read
        print(f"First few rows in {filename}:\n", df.head())

        # Use the filename (without extension) as the sheet name
        sheet_name = os.path.splitext(filename)[0]

        # Write each CSV as a separate sheet in the Excel file
        df.to_excel(writer, sheet_name=sheet_name[:31], index=False)

print(f"âœ… All CSV files combined into Excel at: {output_excel_path}")

import os
import shutil
import random

# Paths to your original images folder and destination for train, test, valid
input_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images'
train_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/train'
test_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/test'
valid_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/valid'

# Create train, test, valid folders if they don't exist
os.makedirs(train_folder, exist_ok=True)
os.makedirs(test_folder, exist_ok=True)
os.makedirs(valid_folder, exist_ok=True)

# Get all image filenames in the input folder
image_files = [f for f in os.listdir(input_folder) if os.path.isfile(os.path.join(input_folder, f))]

# Shuffle the list of image files to ensure random splitting
random.shuffle(image_files)

# Define split proportions
train_split = 0.7
test_split = 0.15
valid_split = 0.15

# Calculate the number of files for each split
train_size = int(len(image_files) * train_split)
test_size = int(len(image_files) * test_split)
valid_size = len(image_files) - train_size - test_size

# Split the image files
train_images = image_files[:train_size]
test_images = image_files[train_size:train_size + test_size]
valid_images = image_files[train_size + test_size:]

# Function to move files to the respective folder
def move_images(images, destination_folder):
    for image in images:
        src_path = os.path.join(input_folder, image)
        dest_path = os.path.join(destination_folder, image)
        shutil.move(src_path, dest_path)

# Move the images to the respective folders
move_images(train_images, train_folder)
move_images(test_images, test_folder)
move_images(valid_images, valid_folder)

print(f"âœ… Images split into train, test, and valid folders!")
print(f"  - {len(train_images)} images in the train folder")
print(f"  - {len(test_images)} images in the test folder")
print(f"  - {len(valid_images)} images in the valid folder")

import os
import pandas as pd

# Folder containing your CSV files
input_folder = '/content/classNamecsv12'

# Output Excel file path
output_excel_path = './final_combined_annotations.xlsx'

# List to collect DataFrames
all_data = []

# Iterate over all CSVs
for filename in os.listdir(input_folder):
    if filename.endswith('.csv'):
        file_path = os.path.join(input_folder, filename)
        df = pd.read_csv(file_path)

        # Extract image name from filename (e.g., "abc.csv" -> "abc.jpg")
        image_name = os.path.splitext(filename)[0] + '.jpg'

        # Add image name as a new column
        df.insert(0, 'image_name', image_name)

        # Append to the list
        all_data.append(df)

# Concatenate all dataframes into one
combined_df = pd.concat(all_data, ignore_index=True)

# Save to Excel file
combined_df.to_excel(output_excel_path, index=False)

print(f"âœ… Combined all annotations into a single Excel file: {output_excel_path}")

"""checking number of imgs"""

import pandas as pd

df = pd.read_excel('./final_combined_annotations.xlsx')  # Or .csv if that's what you used
print(df['class_name'].value_counts())
print("\nUnique image count per class:")
print(df.groupby('class_name')['image_name'].nunique())

import os

print("CSV files in :/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs")
print(len([f for f in os.listdir('/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs') if f.endswith('.csv')]))

import os
import pandas as pd

# Path to your folder containing multiple CSVs
csv_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs'

# Initialize counter
impacted_tooth_count = 0

# Loop through all CSV files
for file in os.listdir(csv_folder):
    if file.endswith('.csv'):
        df = pd.read_csv(os.path.join(csv_folder, file))
        impacted_tooth_count += (df['class_id'] == 3).sum()

print(f"âœ… Total 'Impacted tooth' annotations (class_id = 3): {impacted_tooth_count}")

"""checking for all class"""

import os
import pandas as pd

# Folder path
csv_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs'

# Set to collect unique class IDs
all_class_ids = set()

# Loop through all CSVs and collect class_id values
for file in os.listdir(csv_folder):
    if file.endswith('.csv'):
        df = pd.read_csv(os.path.join(csv_folder, file))
        if 'class_id' in df.columns:
            all_class_ids.update(df['class_id'].unique())

# Sort and display
all_class_ids = sorted(all_class_ids)
print(f"âœ… Unique class IDs found in dataset: {all_class_ids}")

import os
import pandas as pd

# Input folder where your converted CSVs are
input_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs'

# Base output directory where class-wise folders will be created
output_base = '/content/class_wise_csvs'
os.makedirs(output_base, exist_ok=True)

# Process each CSV file
for filename in os.listdir(input_folder):
    if filename.endswith('_converted.csv'):
        file_path = os.path.join(input_folder, filename)
        df = pd.read_csv(file_path)

        # Get all unique class_ids in this file
        for class_id in df['class_id'].unique():
            # Filter rows for this specific class_id
            filtered_df = df[df['class_id'] == class_id]

            # Prepare output folder for this class
            class_folder = os.path.join(output_base, f'class_{int(class_id)}')
            os.makedirs(class_folder, exist_ok=True)

            # Save filtered CSV for this file
            output_path = os.path.join(class_folder, filename)
            filtered_df.to_csv(output_path, index=False)

print(f"âœ… All class-wise CSVs saved inside: {output_base}")

import os
import pandas as pd

# Mapping from class ID to class name
class_map = {
    0: 'Healthy teeth',
    1: 'Cavity',
    2: 'Impacted Tooth',
    3: 'BDC',
    4: 'Infection',
    5: 'Fractured teeth'
}

# Input and output paths
input_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Original_Data/converted_csvs'
output_base = '/content/class_named_csvs'
os.makedirs(output_base, exist_ok=True)

# Process each CSV file
for filename in os.listdir(input_folder):
    if filename.endswith('_converted.csv'):
        file_path = os.path.join(input_folder, filename)
        df = pd.read_csv(file_path)

        # Replace class_id with class name
        df['class_name'] = df['class_id'].map(class_map)

        # Loop through each class and save separately
        for class_name in df['class_name'].unique():
            filtered_df = df[df['class_name'] == class_name]

            # Create folder for this class name
            class_folder = os.path.join(output_base, class_name.replace(" ", "_"))
            os.makedirs(class_folder, exist_ok=True)

            # Save the filtered CSV
            output_path = os.path.join(class_folder, filename)
            filtered_df.to_csv(output_path, index=False)

print(f"âœ… Class-named CSVs saved in: {output_base}")

import os
import pandas as pd

# Base path where class-wise folders are stored
base_path = '/content/class_wise_csvs'

# Dictionary to hold counts
class_counts = {}

# Loop through each class folder
for class_folder in os.listdir(base_path):
    folder_path = os.path.join(base_path, class_folder)
    if os.path.isdir(folder_path):
        total_rows = 0
        for file in os.listdir(folder_path):
            if file.endswith('.csv'):
                df = pd.read_csv(os.path.join(folder_path, file))
                total_rows += len(df)
        class_counts[class_folder.replace("_", " ")] = total_rows

# Display the results
print("âœ… Annotation count per class:\n")
for class_name, count in class_counts.items():
    print(f"{class_name}: {count}")

import os
import pandas as pd

# Mapping from class ID to class name
class_map = {
    0: 'Healthy teeth',
    1: 'Cavity',
    2: 'Impacted Tooth',
    3: 'BDC/BDR',
    4: 'Infection',
    5: 'Fractured teeth'
}

# Base path where class-wise folders are stored
base_path = '/content/class_named_csvs'

# List to hold data
data = []

# Loop through each class folder
for class_folder in os.listdir(base_path):
    folder_path = os.path.join(base_path, class_folder)
    if os.path.isdir(folder_path):
        # Process each CSV in the class folder
        for file in os.listdir(folder_path):
            if file.endswith('.csv'):
                df = pd.read_csv(os.path.join(folder_path, file))

                # Replace class_id with class_name
                df['class_name'] = df['class_id'].map(class_map)

                # Collect necessary columns and add image name
                df['image_name'] = file  # Add the image name to each row

                # Append relevant columns to the data list
                for _, row in df.iterrows():
                    data.append([row['image_name'], row['class_name'], row['xmin'], row['ymin'], row['xmax'], row['ymax'], row['width'], row['height']])

# Convert the collected data to a DataFrame
df_output = pd.DataFrame(data, columns=['image_name', 'class_name', 'xmin', 'ymin', 'xmax', 'ymax', 'width', 'height'])

# Save to Excel
output_excel_path = '/content/class_image_data.xlsx'
df_output.to_excel(output_excel_path, index=False)

print(f"âœ… Excel file with image data saved at: {output_excel_path}")

"""dropping the healthy teeth and bdr class"""

import os
import pandas as pd

# Mapping from class ID to class name
class_map = {
    0: 'Healthy teeth',
    1: 'Cavity',
    2: 'Impacted Tooth',
    3: 'BDC/BDR',
    4: 'Infection',
    5: 'Fractured teeth'
}

# Folder containing class-wise CSVs
base_path = '/content/class_named_csvs'

# List to collect all rows
data = []

# Loop through each class folder
for class_folder in os.listdir(base_path):
    folder_path = os.path.join(base_path, class_folder)
    if os.path.isdir(folder_path):
        for file in os.listdir(folder_path):
            if file.endswith('.csv'):
                csv_path = os.path.join(folder_path, file)
                df = pd.read_csv(csv_path)

                # Drop rows with class_id 0 (Healthy teeth) and 3 (BDC/BDR)
                df = df[~df['class_id'].isin([0, 3])]

                # Map class_id to class_name
                df['class_name'] = df['class_id'].map(class_map)

                # Add image name
                df['image_name'] = file

                # Select relevant columns
                df_selected = df[['image_name', 'class_name', 'xmin', 'ymin', 'xmax', 'ymax', 'width', 'height']]

                data.append(df_selected)

# Concatenate all into a single DataFrame
final_df = pd.concat(data, ignore_index=True)

# Save to Excel
output_excel = '/content/filtered_class_image_data.xlsx'
final_df.to_excel(output_excel, index=False)

print(f"âœ… Excel file created without 'Healthy teeth' and 'BDC/BDR' classes at: {output_excel}")

import os

# Path to your CSV directory
csv_dir = '/content/class_named_csvs'

# Counter
csv_count = 0

# Loop through subfolders and count CSV files
for root, dirs, files in os.walk(csv_dir):
    for file in files:
        if file.endswith('.csv'):
            csv_count += 1

print(f"ðŸ“„ Total number of CSV files in '{csv_dir}': {csv_count}")

"""spliting the excel file"""

import pandas as pd
import os

# Paths
csv_path = '/content/filtered_class_image_data.xlsx'  # or .csv
train_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/train'
test_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/test'
val_dir = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/valid'

# Read the original Excel or CSV file
if csv_path.endswith('.xlsx'):
    df = pd.read_excel(csv_path)
else:
    df = pd.read_csv(csv_path)

# Assuming your image names are in a column called 'image_name'
# Adjust the column name if different
image_column = 'image_name'

# Helper to get image names from a folder
def get_image_names(folder):
    return set(os.listdir(folder))

# Get image names from folders
train_images = get_image_names(train_dir)
test_images = get_image_names(test_dir)
val_images = get_image_names(val_dir)

# Filter based on image names
train_df = df[df[image_column].isin(train_images)]
test_df = df[df[image_column].isin(test_images)]
val_df = df[df[image_column].isin(val_images)]

# Save to new files
train_df.to_csv('train_data.csv', index=False)
test_df.to_csv('test_data.csv', index=False)
val_df.to_csv('val_data.csv', index=False)

print("CSV files created successfully!")

"""moving the csvs to the respective folders"""

import pandas as pd
import os

# Step 1: Load Excel file
csv_path = '/content/filtered_class_image_data.xlsx'
df = pd.read_excel(csv_path)

# Step 2: Create a new column with updated image names for matching
df['match_name'] = df['image_name'].str.replace('_converted.csv', '.jpg', regex=False)

# Step 3: Define paths to image folders
train_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/train'
test_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/test'
val_folder = '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images/valid'

# Step 4: Get filenames from each folder
def get_image_names(folder):
    return set(os.listdir(folder))

train_images = get_image_names(train_folder)
test_images = get_image_names(test_folder)
val_images = get_image_names(val_folder)

# Step 5: Filter DataFrame for each split
train_df = df[df['match_name'].isin(train_images)]
test_df = df[df['match_name'].isin(test_images)]
val_df = df[df['match_name'].isin(val_images)]

# Step 6: Save to CSVs in respective folders
train_df.to_csv(os.path.join(train_folder, 'train_data.csv'), index=False)
test_df.to_csv(os.path.join(test_folder, 'test_data.csv'), index=False)
val_df.to_csv(os.path.join(val_folder, 'val_data.csv'), index=False)

print("âœ… CSVs saved to their respective image folders.")

import shutil

shutil.make_archive('Resized_Images', 'zip', '/content/dental_AIUBdataset/Dental OPG XRAY Dataset/Resized_Images')

from google.colab import files

files.download('Resized_Images.zip')